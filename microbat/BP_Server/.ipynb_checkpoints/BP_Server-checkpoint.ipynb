{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "602ad23a",
   "metadata": {},
   "source": [
    "## Install All Packages Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b53951ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sockets\n",
      "  Using cached sockets-1.0.0-py3-none-any.whl (4.5 kB)\n",
      "Installing collected packages: sockets\n",
      "Successfully installed sockets-1.0.0\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.23.3-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "     ---------------------------------------- 14.6/14.6 MB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.23.3\n",
      "Collecting igraph\n",
      "  Downloading igraph-0.10.1-cp39-abi3-win_amd64.whl (2.9 MB)\n",
      "     ---------------------------------------- 2.9/2.9 MB 694.0 kB/s eta 0:00:00\n",
      "Collecting texttable>=1.6.2\n",
      "  Using cached texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: texttable, igraph\n",
      "Successfully installed igraph-0.10.1 texttable-1.6.4\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.6.1-cp310-cp310-win_amd64.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 1.5 MB/s eta 0:00:00\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-9.2.0-cp310-cp310-win_amd64.whl (3.3 MB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.5-cp310-cp310-win_amd64.whl (164 kB)\n",
      "     -------------------------------------- 164.1/164.1 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from matplotlib) (1.23.3)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.37.4-py3-none-any.whl (960 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.0.5 cycler-0.11.0 fonttools-4.37.4 kiwisolver-1.4.4 matplotlib-3.6.1 pillow-9.2.0\n",
      "Collecting pyvis\n",
      "  Downloading pyvis-0.3.0.tar.gz (592 kB)\n",
      "     -------------------------------------- 592.8/592.8 kB 1.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: jinja2>=2.9.6 in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from pyvis) (3.0.3)\n",
      "Collecting networkx>=1.11\n",
      "  Downloading networkx-2.8.7-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from pyvis) (8.4.0)\n",
      "Collecting jsonpickle>=1.4.1\n",
      "  Using cached jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: backcall in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from ipython>=5.3.0->pyvis) (63.4.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from ipython>=5.3.0->pyvis) (2.11.2)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
      "Requirement already satisfied: stack-data in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.4.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from ipython>=5.3.0->pyvis) (3.0.20)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from jinja2>=2.9.6->pyvis) (2.1.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.2.2)\n",
      "Requirement already satisfied: asttokens in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.0.5)\n",
      "Requirement already satisfied: executing in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.8.3)\n",
      "Requirement already satisfied: six in c:\\users\\arkwa\\anaconda3\\envs\\debug_simulation\\lib\\site-packages (from asttokens->stack-data->ipython>=5.3.0->pyvis) (1.16.0)\n",
      "Building wheels for collected packages: pyvis\n",
      "  Building wheel for pyvis (setup.py): started\n",
      "  Building wheel for pyvis (setup.py): finished with status 'done'\n",
      "  Created wheel for pyvis: filename=pyvis-0.3.0-py3-none-any.whl size=600233 sha256=43e9413d53b5f7d2d69e4aeb4c2676f030185f986aaf8932deda2a45a52d0217\n",
      "  Stored in directory: c:\\users\\arkwa\\appdata\\local\\pip\\cache\\wheels\\84\\57\\e8\\d47479bd009ffbbf8a7e6a085d2456a823c58684a64830e0ac\n",
      "Successfully built pyvis\n",
      "Installing collected packages: networkx, jsonpickle, pyvis\n",
      "Successfully installed jsonpickle-2.2.0 networkx-2.8.7 pyvis-0.3.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sockets\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install igraph\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install pyvis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd60f51",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01ac51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import time\n",
    "\n",
    "import numpy  as np\n",
    "import igraph as ig\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc(\"text\", usetex=True)\n",
    "\n",
    "%run ./2-ImplementationFactor.ipynb\n",
    "%run ./3-ImplementationPGM.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab7757",
   "metadata": {},
   "source": [
    "## Environment Configuration\n",
    "\n",
    "The configuration of the environment include:\n",
    "- HOST, PORT: Server setting\n",
    "- ENCODING_METHOD: Encoding method for the message communicate (do not change)\n",
    "- BUFFER_SIZE: Buffer size for server and client (do not change)\n",
    "- END, MSG_BREAK, DILIMITER_1, DILIMITER_2, MUL_SIGN, STATEMENT_ID_PREFIX: Setting for the message (do not change)\n",
    "- MAX_ITR: Maximum iteration run by the loopy belief propagation if it does not converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acea654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server setting\n",
    "HOST = \"127.0.0.1\"\n",
    "PORT = 8080\n",
    "\n",
    "# Encoding method\n",
    "ENCODING_METHOD = \"UTF-8\"\n",
    "\n",
    "# Buffer size for the message\n",
    "BUFFER_SIZE = pow(2, 20)\n",
    "\n",
    "# Setting for the message\n",
    "END = \"END\"\n",
    "MSG_BREAK = \"BREAK\"\n",
    "DILIMITER_1 = ','\n",
    "DILIMITER_2 = \"&\"\n",
    "MUL_SIGN = '*'\n",
    "STATEMENT_ID_PREFIX = \"S_\"\n",
    "\n",
    "# Maximum iteration\n",
    "MAX_ITR = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae5998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class loopy_belief_propagation():\n",
    "    def __init__(self, pgm):\n",
    "        if type(pgm) is not factor_graph:\n",
    "            raise Exception('PGM is not a factor graph')\n",
    "        if not pgm.is_connected():\n",
    "            print(\"[Warning] graph is not connected\")\n",
    "        \n",
    "        self.__t       = 0\n",
    "        self.__msg     = {}\n",
    "        self.__msg_new = {}\n",
    "        self.__pgm     = pgm\n",
    "        self.threshold = 1e-4\n",
    "        \n",
    "        # Initialization of messages\n",
    "        # Set all the message to one\n",
    "        for edge in self.__pgm.get_graph().es:\n",
    "            start_index, end_index = edge.tuple[0], edge.tuple[1]\n",
    "            start_name, end_name = self.__pgm.get_graph().vs[start_index]['name'], self.__pgm.get_graph().vs[end_index]['name']\n",
    "            \n",
    "            if self.__pgm.get_graph().vs[start_index]['is_factor']:\n",
    "                self.__msg[(start_name, end_name)] = factor([end_name],   np.array([1.]*self.__pgm.get_graph().vs[end_index]['rank']))\n",
    "            else:\n",
    "                self.__msg[(start_name, end_name)] = factor([start_name], np.array([1.]*self.__pgm.get_graph().vs[start_index]['rank']))\n",
    "            self.__msg[(end_name, start_name)] = self.__msg[(start_name, end_name)]\n",
    "            \n",
    "            self.__msg_new[(start_name, end_name)] = 0\n",
    "            self.__msg_new[(end_name, start_name)] = 0\n",
    "    \n",
    "    # Get marginal propability of target variables\n",
    "    def belief(self, v_names, num_iter):\n",
    "        if self.__t > num_iter:\n",
    "            raise Exception('Invalid number of iterations. Current number: ' + str(self.__t))\n",
    "        elif self.__t < num_iter:\n",
    "            self.__loop(num_iter)\n",
    "        \n",
    "        margProb = {}\n",
    "        for v_name in v_names:\n",
    "            \n",
    "            incoming_messages = []\n",
    "            for f_name_neighbor in self.__pgm.get_graph().vs[self.__pgm.get_graph().neighbors(v_name)]['name']:\n",
    "                incoming_messages.append(self.get_factor2variable_msg(f_name_neighbor, v_name))\n",
    "        \n",
    "            prob = self.__normalize_msg(joint_distribution(incoming_messages))\n",
    "            margProb[v_name] = prob.get_distribution()[1]\n",
    "\n",
    "        return margProb\n",
    "    \n",
    "    # ----------------------- Variable to factor ------------\n",
    "    def get_variable2factor_msg(self, v_name, f_name):\n",
    "        return self.__msg[(v_name, f_name)]\n",
    "    \n",
    "    def __compute_variable2factor_msg(self, v_name, f_name):\n",
    "        incoming_messages = []\n",
    "        for f_name_neighbor in self.__pgm.get_graph().vs[self.__pgm.get_graph().neighbors(v_name)]['name']:\n",
    "            if f_name_neighbor != f_name:\n",
    "                incoming_messages.append(self.get_factor2variable_msg(f_name_neighbor, v_name))\n",
    "        \n",
    "        if not incoming_messages:\n",
    "            return factor([v_name], np.array([1]*self.__pgm.get_graph().vs.find(name=v_name)['rank']))\n",
    "        else:\n",
    "            return self.__normalize_msg(joint_distribution(incoming_messages))\n",
    "    \n",
    "    # ----------------------- Factor to variable ------------\n",
    "    def get_factor2variable_msg(self, f_name, v_name):\n",
    "        return self.__msg[(f_name, v_name)]\n",
    "    \n",
    "    def __compute_factor2variable_msg(self, f_name, v_name):\n",
    "        incoming_messages = [self.__pgm.get_graph().vs.find(f_name)['factor_']]\n",
    "        marginalization_variables = []\n",
    "        for v_name_neighbor in self.__pgm.get_graph().vs[self.__pgm.get_graph().neighbors(f_name)]['name']:\n",
    "            if v_name_neighbor != v_name:\n",
    "                incoming_messages.append(self.get_variable2factor_msg(v_name_neighbor, f_name))\n",
    "                marginalization_variables.append(v_name_neighbor)\n",
    "        return self.__normalize_msg(factor_marginalization(\n",
    "            joint_distribution(incoming_messages),\n",
    "            marginalization_variables\n",
    "        ))\n",
    "    \n",
    "    # ----------------------- Other -------------------------\n",
    "    def __loop(self, num_iter):\n",
    "        # Message updating\n",
    "        isConverge = False\n",
    "        while self.__t < num_iter and not isConverge:\n",
    "            for edge in self.__pgm.get_graph().es:\n",
    "                start_index, end_index = edge.tuple[0], edge.tuple[1]\n",
    "                start_name, end_name   = self.__pgm.get_graph().vs[start_index]['name'], self.__pgm.get_graph().vs[end_index]['name']\n",
    "                if self.__pgm.get_graph().vs[start_index]['is_factor']:\n",
    "                    self.__msg_new[(start_name, end_name)] = self.__compute_factor2variable_msg(start_name, end_name) if not str(start_name).startswith(STATEMENT_ID_PREFIX) else factor([start_name], np.array([0.5, 0.5]))\n",
    "                    self.__msg_new[(end_name, start_name)] = self.__compute_variable2factor_msg(end_name, start_name)\n",
    "                else:\n",
    "                    self.__msg_new[(start_name, end_name)] = self.__compute_variable2factor_msg(start_name, end_name) if not str(start_name).startswith(STATEMENT_ID_PREFIX) else factor([start_name], np.array([0.5, 0.5]))\n",
    "                    self.__msg_new[(end_name, start_name)] = self.__compute_factor2variable_msg(end_name, start_name)\n",
    "            converge = True\n",
    "            for (start_name, end_name), new_msg in self.__msg_new.items():\n",
    "                old_msg = self.__msg[(start_name, end_name)]\n",
    "                if (abs(old_msg.get_distribution() - new_msg.get_distribution()) > self.threshold).sum() == old_msg.get_distribution().size:\n",
    "                    converge = False\n",
    "            \n",
    "            isConverge = converge\n",
    "            \n",
    "            self.__msg.update(self.__msg_new)\n",
    "            self.__t += 1\n",
    "    \n",
    "    def __normalize_msg(self, message):\n",
    "        return factor(message.get_variables(), message.get_distribution()/np.sum(message.get_distribution()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3afdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorLoader(factor_input):\n",
    "    tokens = factor_input.split(DILIMITER_2)\n",
    "    for idx in range(0, len(tokens), 4):\n",
    "        yield tokens[idx], tokens[idx+1], tokens[idx+2], tokens[idx+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733d5686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printGraphInput(str_):\n",
    "    print(\"graph input:\")\n",
    "    str_tokens = [i.split('(') for i in str_.split(')') if i != '']\n",
    "    for token in str_tokens:\n",
    "        print(token[0], token[1].split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612baf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkDuplicateVar(str_):\n",
    "    str_tokens = [i.split('(') for i in str_.split(')') if i != '']\n",
    "    for token in str_tokens:\n",
    "        vars = token[1].split(',')\n",
    "        if len(vars) != len(set(vars)):\n",
    "            print(\"contain duplicate variables: \", token[0])\n",
    "            print(vars)\n",
    "            raise ValueError('Duplicated variables: ' + token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515d2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printFactorInput(factor_input):\n",
    "    print(\"factor input:\")\n",
    "    tokens = factor_input.split(DILIMITER_2)\n",
    "    for idx in range(0, len(tokens), 4):\n",
    "        print(\"Node:\", tokens[idx], tokens[idx+1], tokens[idx+2], tokens[idx+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e30fd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recvMsg(conn):\n",
    "    graph_input = \"\"\n",
    "    factor_input = \"\"\n",
    "    \n",
    "    # Read Graph Input\n",
    "    while True:\n",
    "        message = conn.recv(BUFFER_SIZE)\n",
    "        if not message:\n",
    "            return None, None\n",
    "        message_str = message.decode(ENCODING_METHOD)\n",
    "        if message_str == MSG_BREAK:\n",
    "            break\n",
    "        else:\n",
    "            graph_input += message_str\n",
    "    \n",
    "    # Read Factor Input\n",
    "    while True:\n",
    "        message = conn.recv(BUFFER_SIZE)\n",
    "        if not message:\n",
    "            return None, None\n",
    "        message_str = message.decode(ENCODING_METHOD)\n",
    "        if message_str == MSG_BREAK:\n",
    "            break\n",
    "        else:\n",
    "            factor_input += message_str\n",
    "    \n",
    "    print(\"graph input size: \", len(graph_input))\n",
    "    print(\"factor input size: \", len(factor_input))\n",
    "    \n",
    "    return graph_input, factor_input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b238f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printNodeCount(graph):\n",
    "    factor_node_count = 0\n",
    "    var_node_count = 0\n",
    "    \n",
    "    for i in range(graph.vcount()):\n",
    "        if graph.vs[i]['is_factor']:\n",
    "            factor_node_count += 1\n",
    "        else:\n",
    "            var_node_count += 1\n",
    "            \n",
    "    print(\"var node count:\", var_node_count, \"factor node count:\", factor_node_count, \"total:\", factor_node_count + var_node_count)\n",
    "    print(\"edges count:\", graph.ecount())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c50b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startServer():\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.bind((HOST, PORT))\n",
    "        stillWorking = True\n",
    "        while stillWorking:\n",
    "            s.listen()\n",
    "            conn, addr = s.accept()\n",
    "            with conn:\n",
    "                print(f\"Connected by {addr}\")\n",
    "\n",
    "                while True:\n",
    "                    print(\"-\"*20)\n",
    "                    graph_input, factor_input = recvMsg(conn)\n",
    "                    \n",
    "                    if not graph_input or not factor_input:\n",
    "#                         print(\"Error: Graph input or factor input is null\")\n",
    "                        response = \"\".encode(ENCODING_METHOD)\n",
    "                        conn.sendall(response)\n",
    "                        break\n",
    "\n",
    "#                     graph_input = graph_input.decode(ENCODING_METHOD)\n",
    "#                     factor_input = factor_input.decode(ENCODING_METHOD)\n",
    "                    \n",
    "                    \n",
    "#                     print(\"graph_input\", graph_input)\n",
    "#                     print(\"factor_input\", factor_input)\n",
    "#                     printGraphInput(graph_input)\n",
    "#                     printFactorInput(factor_input)\n",
    "        \n",
    "                    checkDuplicateVar(graph_input)\n",
    "                    if graph_input == END and factor_input == END:\n",
    "                        output_str = END\n",
    "                        response = output_str.encode(ENCODING_METHOD)\n",
    "                        print(\"response:\", response)\n",
    "                        conn.sendall(response)\n",
    "                        print(\"Terminate server...\")\n",
    "                        stillWorking = False\n",
    "                        break\n",
    "\n",
    "                    fg = string2factor_graph(graph_input)\n",
    "\n",
    "                    predIDs_all = set()\n",
    "                    for order, constraintID, predIDs_str, probs_str in factorLoader(factor_input):\n",
    "                        try:\n",
    "                            predIDs = predIDs_str.split(DILIMITER_1)\n",
    "\n",
    "        #                     print(predIDs)\n",
    "                            predIDs_all.update(predIDs)\n",
    "                            predCount = len(predIDs)\n",
    "\n",
    "                            shape = [2 for _ in range(predCount)]\n",
    "                            shape = tuple(shape)\n",
    "\n",
    "                            probs_tokens = probs_str.split(DILIMITER_1)\n",
    "                            \n",
    "                            probs = []\n",
    "                            for probs_token in probs_tokens:\n",
    "                                probs_str, count = probs_token.split(MUL_SIGN)\n",
    "                                count = int(count)\n",
    "                                prob = float(probs_str)\n",
    "                                for _ in range(count):\n",
    "                                    probs.append(prob)\n",
    "                                    \n",
    "                            probs = np.array(probs)\n",
    "                            probs = probs.reshape(shape)\n",
    "\n",
    "                            fg.change_factor_distribution(constraintID, factor(predIDs,  probs))\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                            print(\"constraintID:\", constraintID)\n",
    "                            print(\"predIDs_str:\", predIDs_str)\n",
    "                            print(\"probs_str:\", probs_str)\n",
    "                            return\n",
    "\n",
    "                    printNodeCount(fg.get_graph())\n",
    "                            \n",
    "                    lbp = loopy_belief_propagation(fg)\n",
    "                    start = time.time()\n",
    "                    margProb = lbp.belief(predIDs_all, MAX_ITR)\n",
    "                    end = time.time()\n",
    "                    \n",
    "                    print(\"time needed: \", end - start)\n",
    "                    plot_factor_graph(fg)\n",
    "                    output_str = \"\"\n",
    "                    for predID, prob in margProb.items():\n",
    "#                         print(predID, prob)\n",
    "                        output_str += predID + DILIMITER_1 + str(prob)\n",
    "                        output_str += DILIMITER_2\n",
    "\n",
    "                    output_str = output_str[:-1]\n",
    "                    response = output_str.encode(ENCODING_METHOD)\n",
    "#                     print(\"response:\", response)\n",
    "                    conn.sendall(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7697f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "startServer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4458d355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc781c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db088f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
